version: "3"

# 首次运行参看　hadoop-compose.yml

services:
   hadoop1:
     image: th9976/hbase
     container_name: hadoop1
     hostname: hadoop1
     restart: always
     deploy:
       mode: global
     environment:
       #slaves: hadoop2,hadoop3 # hadoop 2
       workers: hadoop1,hadoop2,hadoop3 # hadoop 3
       regionservers: hadoop1,hadoop2,hadoop3
       masters: hadoop1,hadoop2,hadoop3
       start: wait-for-it.sh hadoop2/hadoop3 & start-dfs.sh && start-yarn.sh && start-hbase.sh
     depends_on:
       - hadoop2
       - hadoop3
      # 端口 https://blog.csdn.net/shuoyu816/article/details/90573676
     ports:
       - "58020:8020" # hdfs rpc
       - "59870:9870" # nameNode http
       - "59866:9866" # dataNode http
       - "59864:9864" # dataNode rpc
       - "16000:16000" # RegionServer接入
       - "16010:16010" # 集群监控
       - "16020:16020" # 客户端接入
       - "16030:16030" # 节点监控
     tty: true
     volumes:
       - /d/docker/hadoop/data1:/home/data
       - /d/docker/hadoop/data1/logs/hbase:/usr/local/hbase/logs
       - /d/docker/hadoop/data1/logs/hadoop:/usr/local/hadoop/logs
       - ./wait-for-it.sh:/bin/wait-for-it.sh
     networks:
       default:
         ipv4_address: 172.16.16.70
   
   hadoop2:
     image: th9976/hbase
     container_name: hadoop2
     hostname: hadoop2
     restart: always
     deploy:
       mode: global
     environment:
       workers: hadoop1,hadoop2,hadoop3
       regionservers: hadoop1,hadoop2,hadoop3
       masters: hadoop1,hadoop2,hadoop3
     tty: true  
     stdin_open: true
     volumes:
       - /d/docker/hadoop/data2:/home/data
       - /d/docker/hadoop/data2/logs/hbase:/usr/local/hbase/logs
       - /d/docker/hadoop/data2/logs/hadoop:/usr/local/hadoop/logs
     networks:
       default:
         ipv4_address: 172.16.16.71
         
   hadoop3:
    image: th9976/hbase
    container_name: hadoop3
    hostname: hadoop3
    restart: always
    deploy:
      mode: global
    environment:
      workers: hadoop1,hadoop2,hadoop3
      regionservers: hadoop1,hadoop2,hadoop3
      masters: hadoop1,hadoop2,hadoop3
    tty: true
    stdin_open: true
    volumes:
      - /d/docker/hadoop/data3:/home/data
      - /d/docker/hadoop/data3/logs/hbase:/usr/local/hbase/logs
      - /d/docker/hadoop/data3/logs/hadoop:/usr/local/hadoop/logs
    networks:
      default:
        ipv4_address: 172.16.16.72

# 引用已经存在网络
# docker network create --subnet=172.16.16.0/24 mynetwork
networks:
  default:
    external:
      name: mynetwork